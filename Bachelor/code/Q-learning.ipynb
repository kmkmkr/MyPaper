{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nkmur/.pyenv/versions/3.9.7/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:31: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (8, 8)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import creversi.gym_reversi\n",
    "from creversi import *\n",
    "from itertools import count\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 2000\n",
    "ALPHA = 0.3\n",
    "\n",
    "env = gym.make('Reversi-v0').unwrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QFunc:\n",
    "    def __init__(self, alpha=ALPHA, gamma=GAMMA, initial_q = 1.0):\n",
    "        self._initial_q = initial_q\n",
    "        self._values = {}\n",
    "        self._alpha = alpha\n",
    "        self._gamma = gamma\n",
    "\n",
    "    def get(self, state, act):\n",
    "        if self._values.get((state, act)) is None:\n",
    "            # self._values[(state, act)] = self._initial_q\n",
    "            return self._initial_q\n",
    "        return self._values.get((state, act))\n",
    "\n",
    "    def set(self, s, a, q_value):\n",
    "        self._values[s, a] = q_value\n",
    "\n",
    "    def update(self, s, a, r, max_q):\n",
    "        # print(a)\n",
    "        pQ = self.get(s, a)\n",
    "        new_q = pQ + self._alpha * ((r + self._gamma * max_q) - pQ)\n",
    "        # print(s)\n",
    "        # print(new_q)\n",
    "        self.set(s, a, new_q)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAgent:\n",
    "    def __init__(self):\n",
    "        self.q = QFunc()\n",
    "        self.name = \"QA\"\n",
    "        # self.action_count = 0\n",
    "        self.last_state = ()\n",
    "        self.last_move = -1\n",
    "    def select_move(self,board, episode):\n",
    "        return self.policy(board, episode)\n",
    "\n",
    "    def get_bitboard(self,board):\n",
    "        bitboard = np.empty(1, creversi.dtypeBitboard)\n",
    "        board.to_bitboard(bitboard)\n",
    "        state = tuple(bitboard[0])#ndarray->hashableに変換\n",
    "        return state\n",
    "    \n",
    "    def policy(self,board, episode):#方策\n",
    "        positions = list(board.legal_moves)\n",
    "        state = self.get_bitboard(board)\n",
    "        # if len(positions) == 0:\n",
    "        #     return \"pass\"\n",
    "\n",
    "        sample = random.random()\n",
    "        eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * episode / EPS_DECAY)\n",
    "        if sample < eps_threshold:\n",
    "            move = random.choice(positions)\n",
    "        else:\n",
    "            qs = []\n",
    "            for position in positions:\n",
    "                # qs.append(self.q.get(tuple(self._last_board.flattend_data()), position))#候補手毎のQ値\n",
    "                qs.append(self.q.get(state, position))\n",
    "\n",
    "            max_q = max(qs) ##最も評価が高い手\n",
    "\n",
    "            if qs.count(max_q) > 1:\n",
    "                # more than 1 best option; choose among them randomly\n",
    "                best_options = [i for i in range(len(positions)) if qs[i] == max_q]\n",
    "                i = random.choice(best_options)\n",
    "            else:\n",
    "                i = qs.index(max_q)\n",
    "            move = positions[i]\n",
    "        self.last_state = state\n",
    "        self.last_move = move\n",
    "        return move\n",
    "    \n",
    "\n",
    "    def learn(self, board, move, reward, next_board, done, max_next_q):#Q学習\n",
    "        state = self.get_bitboard(board)\n",
    "        # next_q_list = []\n",
    "        # next_state = self.get_bitboard(next_board)\n",
    "        # next_moves = list(next_board.legal_moves)\n",
    "        # for legal_next_move in next_moves:\n",
    "        #     next_q_list.append(self.q.get(next_state, legal_next_move))\n",
    "\n",
    "        # if done or len(next_q_list) == 0:\n",
    "        #     max_q_new = 0\n",
    "        # else:\n",
    "        #     max_q_new = max(next_q_list)\n",
    "        # max_q_new = -max_q_new\n",
    "        self.q.update(self.last_state, self.last_move, reward, max_next_q)\n",
    "\n",
    "\n",
    "class RandomAgent:\n",
    "    def __init__(self):\n",
    "        # self.board = board\n",
    "        self.last_board = None\n",
    "        self.last_move = None\n",
    "        self.name = \"RA\"\n",
    "    def select_move(self, board, episode):\n",
    "        list_move = list(board.legal_moves)\n",
    "        # rand_move_num = random.randint(0,len(list_move)-1)\n",
    "        move = random.choice(list_move)\n",
    "        return move\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_process(results, board ,episode):\n",
    "        if board.turn == BLACK_TURN:\n",
    "            piece_nums = [board.piece_num(), board.opponent_piece_num()]\n",
    "        else:\n",
    "            piece_nums = [board.opponent_piece_num(), board.piece_num()]\n",
    "\n",
    "        # print(f'result black={piece_nums[0]} white={piece_nums[1]}')\n",
    "        if piece_nums[0] > piece_nums[1]:\n",
    "            # print('black won')\n",
    "            results[0]+=1\n",
    "        elif piece_nums[1] > piece_nums[0]:\n",
    "            # print('white won')\n",
    "           results[1]+=1\n",
    "        else:\n",
    "            # print('draw')\n",
    "            results[2]+=1\n",
    "            \n",
    "        if episode%500==0:\n",
    "            print(f\"Black:{results[0]} White:{results[1]} even:{results[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_next_q(agent, next_board, done):\n",
    "    next_q_list = []\n",
    "    next_state = agent.get_bitboard(next_board)\n",
    "    next_moves = list(next_board.legal_moves)\n",
    "    for legal_next_move in next_moves:\n",
    "        next_q_list.append(agent.q.get(next_state, legal_next_move))\n",
    "\n",
    "    if done or len(next_q_list) == 0:\n",
    "        max_next_q = 0.0\n",
    "    else:\n",
    "        max_next_q = max(next_q_list)\n",
    "    max_next_q = max_next_q\n",
    "    return max_next_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black:1 White:0 even:0\n",
      "Black:240 White:237 even:24\n",
      "Black:460 White:499 even:42\n",
      "Black:690 White:740 even:71\n",
      "Black:939 White:972 even:90\n",
      "Black:1159 White:1234 even:108\n",
      "Black:1387 White:1484 even:130\n",
      "Black:1624 White:1728 even:149\n",
      "Black:1834 White:1996 even:171\n",
      "Black:2070 White:2241 even:190\n",
      "Black:2288 White:2499 even:214\n",
      "Black:2524 White:2749 even:228\n",
      "Black:2750 White:2994 even:257\n",
      "Black:2973 White:3247 even:281\n",
      "Black:3210 White:3491 even:300\n",
      "Black:3435 White:3746 even:320\n",
      "Black:3645 White:4005 even:351\n",
      "Black:3896 White:4228 even:377\n",
      "Black:4120 White:4493 even:388\n",
      "Black:4350 White:4736 even:415\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 10000\n",
    "episodes_done = 0\n",
    "Black = QAgent()\n",
    "# White = QAgent() \n",
    "White = RandomAgent()\n",
    "results=[0,0,0]\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 2000\n",
    "max_next_q = 0\n",
    "for i_episode in range(num_episodes):\n",
    "    env.reset()\n",
    "    # last_move = 64\n",
    "    # last_board = None\n",
    "    # reward = 0\n",
    "    # done = False\n",
    "    b = 0\n",
    "    w = 0\n",
    "    for t in count():\n",
    "        \n",
    "        b_move = Black.select_move(env.board, i_episode)\n",
    "        b_board = copy.copy(env.board)#石を打つ前に状態保存\n",
    "        # print(board)\n",
    "        b_next_board, reward, done, is_draw = env.step(b_move)\n",
    "        # print(board)\n",
    "        # print(env.board)\n",
    "        # print(f\"b_reward={reward}\")\n",
    "        # print(f\"b_move={b_move}\")\n",
    "        # print(f\"Black.last_move={Black.last_move}\")\n",
    "\n",
    "        if White.name == \"QA\" and White.last_move in range(64):\n",
    "            # max_next_q = get_max_next_q(Black, next_board, done)\n",
    "            max_next_q = get_max_next_q(White, b_next_board, done)\n",
    "            White.learn(w_board, w_move, reward, b_next_board, done ,max_next_q)\n",
    "            w += 1\n",
    "            # print(f\"w = {w}\")\n",
    "        \n",
    "        if done and Black.last_move==64:\n",
    "            break\n",
    "\n",
    "        w_move = White.select_move(env.board, i_episode)\n",
    "        w_board = copy.copy(env.board)\n",
    "        w_next_board, reward, done, is_draw = env.step(w_move)\n",
    "        # print(f\"w_reward={reward}\")\n",
    "        # print(f\"White.last_move={White.last_move}\")\n",
    "\n",
    "        if Black.name == \"QA\" and Black.last_move in range(64):#pass->64\n",
    "            # max_next_q = get_max_next_q(White, next_board, done)\n",
    "            max_next_q = get_max_next_q(Black, w_next_board, done)\n",
    "            Black.learn(b_board, b_move, reward, w_next_board, done,max_next_q)\n",
    "            b += 1\n",
    "            # print(f\"b = {b}\")\n",
    "\n",
    "        if done and White.last_move==64:\n",
    "            break\n",
    "    # record_result(results, env.board, i_episode)\n",
    "    result_process(results, env.board, i_episode)\n",
    "    episodes_done += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 性能評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black:1 White:0 even:0\n",
      "Black:231 White:252 even:18\n",
      "Black:456 White:505 even:40\n",
      "Black:668 White:770 even:63\n",
      "Black:880 White:1036 even:85\n",
      "Black:1114 White:1281 even:106\n",
      "Black:1334 White:1543 even:124\n",
      "Black:1553 White:1799 even:149\n",
      "Black:1767 White:2060 even:174\n",
      "Black:2017 White:2288 even:196\n",
      "Black:2233 White:2543 even:225\n",
      "Black:2456 White:2791 even:254\n",
      "Black:2685 White:3041 even:275\n",
      "Black:2922 White:3287 even:292\n",
      "Black:3161 White:3532 even:308\n",
      "Black:3383 White:3795 even:323\n",
      "Black:3612 White:4044 even:345\n",
      "Black:3838 White:4301 even:362\n",
      "Black:4075 White:4543 even:383\n",
      "Black:4298 White:4799 even:404\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 10000\n",
    "episodes_done = 0\n",
    "# Black = QAgent()\n",
    "White_R = RandomAgent()\n",
    "results=[0,0,0]\n",
    "EPS_START = 0\n",
    "EPS_END = 0\n",
    "EPS_DECAY = 1\n",
    "for i_episode in range(num_episodes):\n",
    "    env.reset()\n",
    "    \n",
    "    for t in count():\n",
    "\n",
    "        b_move = Black.select_move(env.board, i_episode)\n",
    "        next_board, reward, done, is_draw = env.step(b_move)\n",
    "\n",
    "        w_move = White_R.select_move(env.board, i_episode)\n",
    "        next_board, reward, done, is_draw = env.step(w_move)\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "    result_process(results, env.board, i_episode)\n",
    "    episodes_done += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### White"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black:0 White:1 even:0\n",
      "Black:217 White:264 even:20\n",
      "Black:442 White:519 even:40\n",
      "Black:682 White:757 even:62\n",
      "Black:895 White:1025 even:81\n",
      "Black:1121 White:1271 even:109\n",
      "Black:1338 White:1534 even:129\n",
      "Black:1543 White:1806 even:152\n",
      "Black:1765 White:2067 even:169\n",
      "Black:1993 White:2319 even:189\n",
      "Black:2223 White:2569 even:209\n",
      "Black:2457 White:2811 even:233\n",
      "Black:2694 White:3054 even:253\n",
      "Black:2917 White:3311 even:273\n",
      "Black:3142 White:3558 even:301\n",
      "Black:3389 White:3797 even:315\n",
      "Black:3593 White:4074 even:334\n",
      "Black:3812 White:4339 even:350\n",
      "Black:4047 White:4584 even:370\n",
      "Black:4275 White:4827 even:399\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 10000\n",
    "episodes_done = 0\n",
    "# Black = QAgent()\n",
    "Black_R = RandomAgent()\n",
    "results=[0,0,0]\n",
    "EPS_START = 0\n",
    "EPS_END = 0\n",
    "EPS_DECAY = 1\n",
    "for i_episode in range(num_episodes):\n",
    "    env.reset()\n",
    "    \n",
    "    for t in count():\n",
    "\n",
    "        b_move = Black_R.select_move(env.board, i_episode)\n",
    "        next_board, reward, done, is_draw = env.step(b_move)\n",
    "\n",
    "        w_move = White.select_move(env.board, i_episode)\n",
    "        next_board, reward, done, is_draw = env.step(w_move)\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "    result_process(results, env.board, i_episode)\n",
    "    episodes_done += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('3.9.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08279f195b146fee57697b9c09fcf929118a6f6448153d815c24aea3815d7442"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
